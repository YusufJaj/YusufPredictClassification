{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-12T13:08:07.621303Z","iopub.execute_input":"2022-10-12T13:08:07.621693Z","iopub.status.idle":"2022-10-12T13:08:07.636498Z","shell.execute_reply.started":"2022-10-12T13:08:07.621611Z","shell.execute_reply":"2022-10-12T13:08:07.634592Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/edsa-sentiment-classification/sample_submission.csv\n/kaggle/input/edsa-sentiment-classification/train.csv\n/kaggle/input/edsa-sentiment-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To begin with, we will import all the relevant libraries\nIn building this model, we will be using libraries for the following purposes\n- Data Cleaning\n- Exploratory Data Analysis\n- Natural Language Toolkit\n- Mathematical functions\n- Data Processing\n- Model Building\n- Plotting\n","metadata":{}},{"cell_type":"code","source":"#Collecting the relevant imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.colors import ListedColormap\n\n#Defining the NLTK Variables\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, TreebankWordTokenizer\nfrom nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('omw-1.4')\nstopwords_list = stopwords.words('english')\n\n#importing all models\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:07.638409Z","iopub.execute_input":"2022-10-12T13:08:07.638931Z","iopub.status.idle":"2022-10-12T13:08:09.152905Z","shell.execute_reply.started":"2022-10-12T13:08:07.638891Z","shell.execute_reply":"2022-10-12T13:08:09.150268Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will then need to connect to the data sets, and create Pandas data frames from the data","metadata":{}},{"cell_type":"code","source":"#Creating data frames for the train and test data sets\ndf_train = pd.read_csv('/kaggle/input/edsa-sentiment-classification/train.csv')\ndf_tr = df_train.copy()\ndf_test = pd.read_csv('/kaggle/input/edsa-sentiment-classification/test.csv')\ndf_te = df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.156211Z","iopub.execute_input":"2022-10-12T13:08:09.156781Z","iopub.status.idle":"2022-10-12T13:08:09.246915Z","shell.execute_reply.started":"2022-10-12T13:08:09.156748Z","shell.execute_reply":"2022-10-12T13:08:09.244643Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Once connected to the data, we should do analysis to ensure that the data is fit for purpose.\nSome of the checks that we are doing are as follows:\n- The properties of the train and test data\n- Viewing the actual Data\n- Cheking for duplicate data\n","metadata":{}},{"cell_type":"code","source":"#Fetching information of the train table\ndf_train.info()\nprint(df_train.shape)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.252473Z","iopub.execute_input":"2022-10-12T13:08:09.252993Z","iopub.status.idle":"2022-10-12T13:08:09.288766Z","shell.execute_reply.started":"2022-10-12T13:08:09.252954Z","shell.execute_reply":"2022-10-12T13:08:09.286120Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 15819 entries, 0 to 15818\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   sentiment  15819 non-null  int64 \n 1   message    15819 non-null  object\n 2   tweetid    15819 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 370.9+ KB\n(15819, 3)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n1          1  It's not like we lack evidence of anthropogeni...   126103\n2          2  RT @RawStory: Researchers say we have three ye...   698562\n3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>It's not like we lack evidence of anthropogeni...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT @RawStory: Researchers say we have three ye...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Fetching information of the test table\ndf_test.info()\nprint(df_test.shape)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.290192Z","iopub.execute_input":"2022-10-12T13:08:09.290516Z","iopub.status.idle":"2022-10-12T13:08:09.317246Z","shell.execute_reply.started":"2022-10-12T13:08:09.290489Z","shell.execute_reply":"2022-10-12T13:08:09.315358Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10546 entries, 0 to 10545\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   message  10546 non-null  object\n 1   tweetid  10546 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 164.9+ KB\n(10546, 2)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             message  tweetid\n0  Europe will now be looking to China to make su...   169760\n1  Combine this with the polling of staffers re c...    35326\n2  The scary, unimpeachable evidence that climate...   224985\n3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Europe will now be looking to China to make su...</td>\n      <td>169760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combine this with the polling of staffers re c...</td>\n      <td>35326</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The scary, unimpeachable evidence that climate...</td>\n      <td>224985</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n      <td>476263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n      <td>872928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Testing the amount of duplicates in the train data\nmessage_dup_count = df_tr['message'].value_counts()\nprint ('-- There are ' + str(df_tr['message'].nunique()) + ' unique records in the message column')\nprint ('-- The value counts of data in the message column is as follows: ')\nprint(message_dup_count)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.319218Z","iopub.execute_input":"2022-10-12T13:08:09.319576Z","iopub.status.idle":"2022-10-12T13:08:09.351952Z","shell.execute_reply.started":"2022-10-12T13:08:09.319547Z","shell.execute_reply":"2022-10-12T13:08:09.350210Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"-- There are 14229 unique records in the message column\n-- The value counts of data in the message column is as follows: \nRT @StephenSchlegel: she's thinking about how she's going to die because your husband doesn't believe in climate change https://t.co/SjoFoNÃ¢â‚¬Â¦    307\nRT @SenSanders: We have a president-elect who doesn't believe in climate change. Millions of people are going to have to say: Mr. TÃ¢â‚¬Â¦            130\nRT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn httÃ¢â‚¬Â¦     73\nRT @BernieSanders: #ImVotingBecause the future of the planet is at stake. Hillary Clinton will combat climate change. Donald Trump thinks iÃ¢â‚¬Â¦     59\nRT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦     56\n                                                                                                                                                     ... \nBernie Sanders: ‘no compromise’ on bigotry, climate change, democracy https://t.co/wJAUBc6LbP                                                           1\nTrump seems to be changing his mind on climate change https://t.co/Ue8OWJo7Gm                                                                           1\nRT @ProfTerryHughes: There's nowhere to hide from global warming: 'Does a new era of bleaching beckon for Indian Ocean coral reefs?' https:…            1\nBecause we have actual evidence the Earth isn't flat. There is NO evidence man made climate change is real. https://t.co/J64fDNdCUZ                     1\nRT @Chet_Cannon: .@kurteichenwald's 'climate change equation' in 4 screenshots https://t.co/lp7UufcxDQ                                                  1\nName: message, Length: 14229, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From the investigation above, we noticed that there are quite a few duplicates. \nTo start off the data cleansing process, we would firstly remove all duplicates\n","metadata":{}},{"cell_type":"code","source":"print('The Shape of the train data before removing duplicates')\nprint(df_tr.shape)\n#Code to drop duplicates\ndf_tr = df_tr.drop_duplicates(subset = 'message' , keep = 'first')\nprint('The Shape of the train data after removing duplicates')\nprint(df_tr.shape)\ndf_tr.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.353623Z","iopub.execute_input":"2022-10-12T13:08:09.353941Z","iopub.status.idle":"2022-10-12T13:08:09.380478Z","shell.execute_reply.started":"2022-10-12T13:08:09.353915Z","shell.execute_reply":"2022-10-12T13:08:09.379512Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The Shape of the train data before removing duplicates\n(15819, 3)\nThe Shape of the train data after removing duplicates\n(14229, 3)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n1          1  It's not like we lack evidence of anthropogeni...   126103\n2          2  RT @RawStory: Researchers say we have three ye...   698562\n3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>It's not like we lack evidence of anthropogeni...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT @RawStory: Researchers say we have three ye...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We also noticed that there was a lot of noise in the data. Noise refers to unneccessary information, such as:\n- @\n- WebUrls\n- Extra WhiteSpace\n- Lower case \n- Remove all other special characters\n\nWe using a concept called regular expression to remove the noise, so that when the data is modelled, it is in a \"cleaner\" state, to make better predictions.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"\n# Remove special characters   \ndf_tr['message'] = df_tr['message'].str.replace('[^\\w\\s]','')  \n# Remove RT\ndf_tr['message'] = df_tr['message'].str.replace('RT','')  \n# Remove url's\ndf_tr['message'] =  df_tr['message'].str.replace(r'https?:\\/\\/.*\\/\\w*', '')\n# Remove hashtags\n#df_tr['message'] = re.sub(r'#\\w*', '', df_tr['message'])    \n# Remove numbers\ndf_tr['message'] =  df_tr['message'].str.replace(r'\\d+', '')  \n# Remove extra whitespace\ndf_tr['message'] =  df_tr['message'].str.replace(r'\\s\\s+', ' ')\n# Remove space in front of tweet\ndf_tr['message'] = df_tr['message'].str.lstrip(' ')     \n# Convert everything to lowercase\ndf_tr['message'] = df_tr['message'].str.lower()\n\ndf_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.382254Z","iopub.execute_input":"2022-10-12T13:08:09.382849Z","iopub.status.idle":"2022-10-12T13:08:09.636151Z","shell.execute_reply.started":"2022-10-12T13:08:09.382808Z","shell.execute_reply":"2022-10-12T13:08:09.634956Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n  if sys.path[0] == \"\":\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n1          1  its not like we lack evidence of anthropogenic...   126103\n2          2  rawstory researchers say we have three years t...   698562\n3          1  todayinmaker wired was a pivotal year in the w...   573736\n4          1  soynoviodetodas its and a racist sexist climat...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>its not like we lack evidence of anthropogenic...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rawstory researchers say we have three years t...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>todayinmaker wired was a pivotal year in the w...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>soynoviodetodas its and a racist sexist climat...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The next step in the data preparation process would be to Tokenize the data. The process of Tokenizing is dividing text in to a sequence of tokens, which enables readiness for modelling","metadata":{}},{"cell_type":"code","source":"#Instantiating the tokenizer, and creating a new column to the df with the tokenized words in a list\ntkn = TreebankWordTokenizer()\ndf_tr['tokens'] = df_tr['message'].apply(tkn.tokenize)\ndf_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:09.637945Z","iopub.execute_input":"2022-10-12T13:08:09.638362Z","iopub.status.idle":"2022-10-12T13:08:10.843377Z","shell.execute_reply.started":"2022-10-12T13:08:09.638323Z","shell.execute_reply":"2022-10-12T13:08:10.841318Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid  \\\n0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n1          1  its not like we lack evidence of anthropogenic...   126103   \n2          2  rawstory researchers say we have three years t...   698562   \n3          1  todayinmaker wired was a pivotal year in the w...   573736   \n4          1  soynoviodetodas its and a racist sexist climat...   466954   \n\n                                              tokens  \n0  [polyscimajor, epa, chief, doesnt, think, carb...  \n1  [its, not, like, we, lack, evidence, of, anthr...  \n2  [rawstory, researchers, say, we, have, three, ...  \n3  [todayinmaker, wired, was, a, pivotal, year, i...  \n4  [soynoviodetodas, its, and, a, racist, sexist,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n      <td>625221</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>its not like we lack evidence of anthropogenic...</td>\n      <td>126103</td>\n      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rawstory researchers say we have three years t...</td>\n      <td>698562</td>\n      <td>[rawstory, researchers, say, we, have, three, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>todayinmaker wired was a pivotal year in the w...</td>\n      <td>573736</td>\n      <td>[todayinmaker, wired, was, a, pivotal, year, i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>soynoviodetodas its and a racist sexist climat...</td>\n      <td>466954</td>\n      <td>[soynoviodetodas, its, and, a, racist, sexist,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Root words are always easier to model, as it batches a few words into a single category. We use the process of stemming to convert words in to the root word","metadata":{}},{"cell_type":"code","source":"#Instantiating the stemmer, and creating a new column in the df with all of the root values\nstemmer = SnowballStemmer('english')\ndef word_stemmer(words, stemmer):\n    return [stemmer.stem(word) for word in words]\n\ndf_tr['Stemmed'] = df_tr['tokens'].apply(word_stemmer,args=(stemmer,))\ndf_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:10.846142Z","iopub.execute_input":"2022-10-12T13:08:10.846672Z","iopub.status.idle":"2022-10-12T13:08:13.722199Z","shell.execute_reply.started":"2022-10-12T13:08:10.846634Z","shell.execute_reply":"2022-10-12T13:08:13.720024Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid  \\\n0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n1          1  its not like we lack evidence of anthropogenic...   126103   \n2          2  rawstory researchers say we have three years t...   698562   \n3          1  todayinmaker wired was a pivotal year in the w...   573736   \n4          1  soynoviodetodas its and a racist sexist climat...   466954   \n\n                                              tokens  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [its, not, like, we, lack, evidence, of, anthr...   \n2  [rawstory, researchers, say, we, have, three, ...   \n3  [todayinmaker, wired, was, a, pivotal, year, i...   \n4  [soynoviodetodas, its, and, a, racist, sexist,...   \n\n                                             Stemmed  \n0  [polyscimajor, epa, chief, doesnt, think, carb...  \n1  [it, not, like, we, lack, evid, of, anthropoge...  \n2  [rawstori, research, say, we, have, three, yea...  \n3  [todayinmak, wire, was, a, pivot, year, in, th...  \n4  [soynoviodetoda, it, and, a, racist, sexist, c...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>tokens</th>\n      <th>Stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n      <td>625221</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>its not like we lack evidence of anthropogenic...</td>\n      <td>126103</td>\n      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rawstory researchers say we have three years t...</td>\n      <td>698562</td>\n      <td>[rawstory, researchers, say, we, have, three, ...</td>\n      <td>[rawstori, research, say, we, have, three, yea...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>todayinmaker wired was a pivotal year in the w...</td>\n      <td>573736</td>\n      <td>[todayinmaker, wired, was, a, pivotal, year, i...</td>\n      <td>[todayinmak, wire, was, a, pivot, year, in, th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>soynoviodetodas its and a racist sexist climat...</td>\n      <td>466954</td>\n      <td>[soynoviodetodas, its, and, a, racist, sexist,...</td>\n      <td>[soynoviodetoda, it, and, a, racist, sexist, c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Following stemming, we are going to lemmatize the data. This is the process of grouping words with a similar meaning, together.","metadata":{}},{"cell_type":"code","source":"#Instantiating the lemma, and creating a new column in the df with all of the lemma values\nlemmatizer = WordNetLemmatizer()\n\ndef word_lemma(words,lemmatizer):\n    return [lemmatizer.lemmatize(word) for word in words]    \n\ndf_tr['lemma'] = df_tr['tokens'].apply(word_lemma,args=(lemmatizer,))\n\ndf_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:13.725237Z","iopub.execute_input":"2022-10-12T13:08:13.725773Z","iopub.status.idle":"2022-10-12T13:08:16.724935Z","shell.execute_reply.started":"2022-10-12T13:08:13.725735Z","shell.execute_reply":"2022-10-12T13:08:16.722718Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid  \\\n0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n1          1  its not like we lack evidence of anthropogenic...   126103   \n2          2  rawstory researchers say we have three years t...   698562   \n3          1  todayinmaker wired was a pivotal year in the w...   573736   \n4          1  soynoviodetodas its and a racist sexist climat...   466954   \n\n                                              tokens  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [its, not, like, we, lack, evidence, of, anthr...   \n2  [rawstory, researchers, say, we, have, three, ...   \n3  [todayinmaker, wired, was, a, pivotal, year, i...   \n4  [soynoviodetodas, its, and, a, racist, sexist,...   \n\n                                             Stemmed  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [it, not, like, we, lack, evid, of, anthropoge...   \n2  [rawstori, research, say, we, have, three, yea...   \n3  [todayinmak, wire, was, a, pivot, year, in, th...   \n4  [soynoviodetoda, it, and, a, racist, sexist, c...   \n\n                                               lemma  \n0  [polyscimajor, epa, chief, doesnt, think, carb...  \n1  [it, not, like, we, lack, evidence, of, anthro...  \n2  [rawstory, researcher, say, we, have, three, y...  \n3  [todayinmaker, wired, wa, a, pivotal, year, in...  \n4  [soynoviodetodas, it, and, a, racist, sexist, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>tokens</th>\n      <th>Stemmed</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n      <td>625221</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>its not like we lack evidence of anthropogenic...</td>\n      <td>126103</td>\n      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rawstory researchers say we have three years t...</td>\n      <td>698562</td>\n      <td>[rawstory, researchers, say, we, have, three, ...</td>\n      <td>[rawstori, research, say, we, have, three, yea...</td>\n      <td>[rawstory, researcher, say, we, have, three, y...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>todayinmaker wired was a pivotal year in the w...</td>\n      <td>573736</td>\n      <td>[todayinmaker, wired, was, a, pivotal, year, i...</td>\n      <td>[todayinmak, wire, was, a, pivot, year, in, th...</td>\n      <td>[todayinmaker, wired, wa, a, pivotal, year, in...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>soynoviodetodas its and a racist sexist climat...</td>\n      <td>466954</td>\n      <td>[soynoviodetodas, its, and, a, racist, sexist,...</td>\n      <td>[soynoviodetoda, it, and, a, racist, sexist, c...</td>\n      <td>[soynoviodetodas, it, and, a, racist, sexist, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We will now remove all \"stop\" words from the lemmatized list. \n\nOnce the stop words are removed, we will then analyze the frequency or words, and select the best fit of data to use for modelling.\nHowever, before doing so, we will analyze the distribution of the stop words and compare them to the total percentage of words to see if it will make an impact to the model. This will guide our decision to either remove some words, or keep them\n","metadata":{}},{"cell_type":"code","source":"#Create a new column removing all stop words from lemma\nfrom nltk.corpus import stopwords\n\ndef remove_stop_words(tokens):    \n    return [t for t in tokens if t not in stopwords.words('english')]\n\ndf_tr['no_stop_words'] = df_tr['lemma'].apply(remove_stop_words)\ndf_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:16.727672Z","iopub.execute_input":"2022-10-12T13:08:16.728059Z","iopub.status.idle":"2022-10-12T13:08:42.348922Z","shell.execute_reply.started":"2022-10-12T13:08:16.728029Z","shell.execute_reply":"2022-10-12T13:08:42.347216Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  tweetid  \\\n0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n1          1  its not like we lack evidence of anthropogenic...   126103   \n2          2  rawstory researchers say we have three years t...   698562   \n3          1  todayinmaker wired was a pivotal year in the w...   573736   \n4          1  soynoviodetodas its and a racist sexist climat...   466954   \n\n                                              tokens  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [its, not, like, we, lack, evidence, of, anthr...   \n2  [rawstory, researchers, say, we, have, three, ...   \n3  [todayinmaker, wired, was, a, pivotal, year, i...   \n4  [soynoviodetodas, its, and, a, racist, sexist,...   \n\n                                             Stemmed  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [it, not, like, we, lack, evid, of, anthropoge...   \n2  [rawstori, research, say, we, have, three, yea...   \n3  [todayinmak, wire, was, a, pivot, year, in, th...   \n4  [soynoviodetoda, it, and, a, racist, sexist, c...   \n\n                                               lemma  \\\n0  [polyscimajor, epa, chief, doesnt, think, carb...   \n1  [it, not, like, we, lack, evidence, of, anthro...   \n2  [rawstory, researcher, say, we, have, three, y...   \n3  [todayinmaker, wired, wa, a, pivotal, year, in...   \n4  [soynoviodetodas, it, and, a, racist, sexist, ...   \n\n                                       no_stop_words  \n0  [polyscimajor, epa, chief, doesnt, think, carb...  \n1  [like, lack, evidence, anthropogenic, global, ...  \n2  [rawstory, researcher, say, three, year, act, ...  \n3  [todayinmaker, wired, wa, pivotal, year, war, ...  \n4  [soynoviodetodas, racist, sexist, climate, cha...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>tokens</th>\n      <th>Stemmed</th>\n      <th>lemma</th>\n      <th>no_stop_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n      <td>625221</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>its not like we lack evidence of anthropogenic...</td>\n      <td>126103</td>\n      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rawstory researchers say we have three years t...</td>\n      <td>698562</td>\n      <td>[rawstory, researchers, say, we, have, three, ...</td>\n      <td>[rawstori, research, say, we, have, three, yea...</td>\n      <td>[rawstory, researcher, say, we, have, three, y...</td>\n      <td>[rawstory, researcher, say, three, year, act, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>todayinmaker wired was a pivotal year in the w...</td>\n      <td>573736</td>\n      <td>[todayinmaker, wired, was, a, pivotal, year, i...</td>\n      <td>[todayinmak, wire, was, a, pivot, year, in, th...</td>\n      <td>[todayinmaker, wired, wa, a, pivotal, year, in...</td>\n      <td>[todayinmaker, wired, wa, pivotal, year, war, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>soynoviodetodas its and a racist sexist climat...</td>\n      <td>466954</td>\n      <td>[soynoviodetodas, its, and, a, racist, sexist,...</td>\n      <td>[soynoviodetoda, it, and, a, racist, sexist, c...</td>\n      <td>[soynoviodetodas, it, and, a, racist, sexist, ...</td>\n      <td>[soynoviodetodas, racist, sexist, climate, cha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#In the code below, we are analysing the amount of words, and their frequency. We aim to further prepare the data for modelling by removing words with a small number of occurences\nsent_labels = list(df_tr.sentiment.unique())\n\ndef bag_of_words_count(words, word_dict={}):\n\n    for word in words:\n        if word in word_dict.keys():\n            word_dict[word] += 1\n        else:\n            word_dict[word] = 1\n    return word_dict\n\nsentiment = {}\nfor sent in sent_labels:\n    df = df_tr.groupby('sentiment')\n    sentiment[sent] = {}\n    for row in df.get_group(sent)['tokens']:\n        sentiment[sent] = bag_of_words_count(row, sentiment[sent])   \n        \nall_words = set()\nfor sent in sent_labels:\n    for word in sentiment[sent]:\n        all_words.add(word)\n\n        \nsentiment['all'] = {}\nfor sent in sent_labels:    \n    for word in all_words:\n        if word in sentiment[sent].keys():\n            if word in sentiment['all']:\n                sentiment['all'][word] += sentiment[sent][word]\n            else:\n                sentiment['all'][word] = sentiment[sent][word]\n                \n#Sum of total words\ntotal_words = sum([v for v in sentiment['all'].values()])\nprint(\"Total number of words: \" + str(total_words))\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:42.353714Z","iopub.execute_input":"2022-10-12T13:08:42.354024Z","iopub.status.idle":"2022-10-12T13:08:42.544749Z","shell.execute_reply.started":"2022-10-12T13:08:42.353998Z","shell.execute_reply":"2022-10-12T13:08:42.540798Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Total number of words: 235853\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From the above function, we will now be able to see which words occur in which frequency bracket. For this, we will see the words that occur less than 10 times","metadata":{}},{"cell_type":"code","source":"_ = plt.hist([v for v in sentiment['all'].values() if v < 10],bins=10)\nplt.ylabel(\"# of words\")\nplt.xlabel(\"word frequency\")\n\none_occur_count = len([v for v in sentiment['all'].values() if v == 1])\nten_plus_count = sum([v for v in sentiment['all'].values() if v >= 10])\ntotal_words = sum([v for v in sentiment['all'].values()])\nprint('There are ' + str(one_occur_count) + ' words that only occur once')\nprint('There are ' + str(ten_plus_count) + ' words that occur more than 10x')","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:42.546487Z","iopub.execute_input":"2022-10-12T13:08:42.547144Z","iopub.status.idle":"2022-10-12T13:08:43.134914Z","shell.execute_reply.started":"2022-10-12T13:08:42.546941Z","shell.execute_reply":"2022-10-12T13:08:43.133617Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"There are 23714 words that only occur once\nThere are 188032 words that occur more than 10x\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Observing the words that occur once\nunique_words = [k for k, v in sentiment['all'].items() if v == 1]\nprint(unique_words[:100])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:43.136695Z","iopub.execute_input":"2022-10-12T13:08:43.137090Z","iopub.status.idle":"2022-10-12T13:08:43.153395Z","shell.execute_reply.started":"2022-10-12T13:08:43.137053Z","shell.execute_reply":"2022-10-12T13:08:43.151778Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['httpstcomdyjmf', 'httpstcoscnxyeahp', 'lizsalandar', 'sophiemcneill', 'effectsãââ', 'ridden', 'repwalterjones', 'openmigration', 'httpstcoihaefovcl', 'greghuntmp', 'rearing', 'transgndr', 'antisame', 'xmas', 'artwork', 'butterflies', 'glenclimate', 'cusson', 'sccscot', 'vocal', 'httpstcomauualpãââ', 'hxppyalien', 'agitatorclimate', 'illuminateboys', 'poln', 'httpstcosxajohmo', 'httpstcolislgcwzl', 'perish', 'httpstcovelnxt', 'booty', 'httpstcopicotcese', 'aleszubajak', 'ctg', 'rileypit', 'climatedeclaration', 'httpstcozhtoqmvv', 'parallels', 'httpstconunqszdfpy', 'pennykilkenny', 'booksellers', 'httpstcornngssose', 'ortega', 'chrismelberger', 'changeno', 'insists', 'httpstcobvedxhfnz', 'alleviate', 'plains', 'nearthe', 'allllll', 'exoanti_', 'httpstcoqtxtpihj', 'catfui', 'pointed', 'httpstcowsgdeanrzo', 'httpstcomkudtcu', 'jesusguerreroh', 'amkmusty', 'httpstcovhwlgud', 'httpstcovinndsd', 'davidschneider', 'httpstcowcqlpiaijc', 'dairyisscary', 'httpstcowbadixl', 'ãåâœâexhibit', 'agents', 'httpstcotgrfopswu', 'usca', 'trumps_taxeslol', 'protest_works', 'citizen', 'agchatoz', 'bettyfckinwhite', 'ethiopian', 'phantompower', 'zmklein', 'httpstcovsyovqh', 'httpstcoecbjrip', 'mpapl', 'httpstcosutyhack', 'httpstcoaddpexiiwo', 'httpstcoqwlddptbsh', 'annakhachiyan', 'httpstcomrkctgkry', 'ashleighhookano', 'asher_wolf', 'carbontaxcenter', 'httpstcoahjnbnzvfw', 'snailphanie', 'greenpeaceindia', 'digg', 'httpstcorejtcudo', 'bitter', 'decryptingtrump', 'dismantled', 'res', 'grappling', 'httpstcoqvxuaxbfdw', 'instabilit', 'httpstcotjxtrrghc']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will now see the percentage of unique words. If the percentage of unique words is too high, we will leave it in the data set. If the percentage is low, we will remove them, as it will not skew the data largely","metadata":{}},{"cell_type":"code","source":"#Computing the percentage of data that constitues words appearing more than 10 times\nten_plus_count/total_words\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:43.154990Z","iopub.execute_input":"2022-10-12T13:08:43.155319Z","iopub.status.idle":"2022-10-12T13:08:43.168170Z","shell.execute_reply.started":"2022-10-12T13:08:43.155294Z","shell.execute_reply":"2022-10-12T13:08:43.166085Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.7972423501079062"},"metadata":{}}]},{"cell_type":"markdown","source":"From the observation above, we notice that 20% of the data constitues words that occur less than 10x. Using the result of this, we will remove all of the words that occur less than 10 times","metadata":{}},{"cell_type":"code","source":"#Removing all words from sentiment where they occur less than 10x\nmax_count = 10\nremaining_word_index = [k for k, v in sentiment['all'].items() if v > max_count]\nprint(remaining_word_index)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:09:16.010868Z","iopub.execute_input":"2022-10-12T13:09:16.011254Z","iopub.status.idle":"2022-10-12T13:09:16.028167Z","shell.execute_reply.started":"2022-10-12T13:09:16.011225Z","shell.execute_reply":"2022-10-12T13:09:16.026417Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"['again', 'form', 'listen', 'happens', 'disappearing', 'storm', 'ivanka', 'falsely', 'part', 'joins', 'share', 'young', 'pruitt', 'disagree', 'ice', 'nothing', 'voting', 'cooperation', 'lack', 'pressure', 'puts', 'melting', 'wsj', 'love', 'beautiful', 'call', 'youve', 'nobody', 'deal', 'renewables', 'exists', 'ideas', 'workers', 'shit', 'earths', 'have', 'cbsnews', 'basically', 'reveal', 'taxpayers', 'break', 'increase', 'racist', 'natural', 'inequality', 'amid', 'join', 'retweet', 'priority', 'result', 'through', 'class', 'theeconomist', 'california', 'rather', 'brought', 'office', 'httpstcãââ', 'roguenasa', 'berniesanders', 'lets', 'forests', 'hes', 'trudeau', 'drive', 'dramatic', 'resilience', 'calling', 'ap', 'profit', 'collapse', 'interior', 'wildlife', 'aint', 'white', 'skepticism', 'longer', 'tweets', 'epa', 'httpãââ', 'e', 'feel', 'based', 'newscientist', 'earthhour', 'plus', 'stories', 'proud', 'truly', 'posts', 'putin', 'low', 'broke', 'generation', 'fuck', 'writes', 'sequel', 'yeah', 'course', 'wants', 'miami', 'group', 'wonder', 'storms', 'family', 'crucial', 'attention', 'oh', 'saw', 'people', 'auspol', 'doe', 'junkscience', 'language', 'cnn', 'signs', 'globe', 'smart', 'using', 'current', 'refugees', 'innovation', 'chicago', 'at', 'dark', 'temperature', 'economist', 'trillion', 'tweeting', 'waste', 'education', 'minimum', 'nodapl', 'become', 'today', 'wall', 'beijing', 'spreading', 'limiting', 'disaster', 'alarming', 'de', 'event', 'american', 'personal', 'met', 'editorial', 'google', 'prove', 'trees', 'being', 'golf', 'launched', 'it', 'interview', 'hard', 'life', 'complex', 'efforts', 'enters', 'curb', 'hunger', 'club', 'president', 'always', 'campaign', 'meat', 'press', 'channel', 'creating', 'wish', 'doctors', 'choice', 'stopping', 'ya', 'pledge', 'line', 'tweeted', 'species', 'age', 'hits', 'paid', 'implications', 'inspiration', 'lead', 'suffering', 'record', 'such', 'perhaps', 'local', 'parisagreement', 'helped', 'victory', 'green', 'https', 'denying', 'theyre', 'washington', 'because', 'millions', 'dept', 'joke', 'girls', 'debate', 'gone', 'raining', 'was', 'globalwarming', 'ecosystem', 'account', 'impact', 'daily', 'insideclimate', 'rate', 'vs', 'agenda', 'data', 'final', 'deluged', 'crazy', 'joined', 'america', 'behind', 'ways', 'effective', 'dangerous', 'severe', 'warmer', 'commitment', 'nonsense', 'ones', 'act', 'when', 'page', 'changeãââ', 'martin', 'usda', 'learn', 'congress', 'drvox', 'youre', 'easy', 'former', 'story', 'remain', 'confused', 'christmas', 'bit', 'project', 'caused', 'countries', 'pakistan', 'poverty', 'trumpãââs', 'flood', 'lives', 'me', 'protect', 'climate', 'cold', 'rise', 'personally', 'measures', 'argument', 'raising', 'almost', 'uproar', 'add', 'use', 'victim', 'individuals', 'for', 'bear', 'administrations', 'third', 'admit', 'has', 'homophobic', 'other', 'right', 'to', 'supposed', 'migration', 'supporters', 'simple', 'convince', 'pope', 'attorney', 'terrifying', 'warns', 'oil', 'dumb', 'na', 'investigation', 'both', 'tax', 'slams', 'ca', 'habitat', 'force', 'trial', 'voted', 'analysis', 'views', 'published', 'health', 'generations', 'plastic', 'bringing', 'failed', 'tell', 'says', 'response', 'planets', 'doubt', 'still', 'things', 'iceberg', 'considering', 'definitely', 'results', 'senior', 'w', 'mine', 'snowing', 'true', 'rules', 'protection', 'needed', 'hillary', 'worldwide', 'photos', 'hands', 'one', 'program', 'schools', 'buzzfeednews', 'heard', 'pr', 'killing', 'respect', 'quite', 'administration', 'post', 'cnnpolitics', 'obamas', 'ppl', 'melt', 'i', 'follow', 'zero', 'growth', 'francis', 'pages', 'destruction', 'trump', 'rapid', 'as', 'tried', 's', 'depression', 'position', 'verge', 'know', 'island', 'had', 'value', 'reality', 'words', 'piece', 'wed', 'asks', 'room', 'experience', 'city', 'theres', 'big', 'scientists', 'look', 'dicaprio', 'died', 'avoid', 'none', 'russia', 'ever', 'gives', 'damage', 'fossil', 'thank', 'chinas', 'understand', 'india', 'head', 'lose', 'sierraclub', 'seeing', 'wayne', 'didnt', 'shifting', 'indigenous', 'imagine', 'turning', 'email', 'middle', 're', 'everything', 'shutting', 'difference', 'urge', 'colorado', 'wanted', 'ivankatrump', 'running', 'names', 'antarctica', 'against', 'bans', 'them', 'addressing', 'message', 'that', 'unless', 'vp', 'pentagon', 'pretty', 'speak', 'diabetes', 'east', 'without', 'flooded', 'harder', 'dr', 'bay', 'doesnt', 'nytimes', 'comments', 'production', 'theresa', 'bangladesh', 'articles', 'demand', 'kamalaharris', 'contribution', 'linked', 'answers', 'question', 'yall', 'congressman', 'regardless', 'according', 'claims', 'interested', 'should', 'voxdotcom', 'meanwhile', 'way', 'abt', 'voice', 'believing', 'asia', 'adapting', 'michael', 'long', 'documentary', 'liberals', 'put', 'huffpostgreen', 'senator', 'sanders', 'becoming', 'harvard', 'sea', 'russian', 'allow', 'living', 'polar', 'whether', 'term', 'from', 'un', 'info', 'board', 'worth', 'predicted', 'gop', 'treaty', 'climatechange', 'ive', 'this', 'wouldnt', 'mind', 'safe', 'era', 'gas', 'perfect', 'cdc', 'ajenglish', 'motherjones', 'bloomberg', 'houston', 'gun', 'goes', 'really', 'donald', 'nearly', 'deserve', 'yo', 'sent', 'came', 'africa', 'maga', 'fox', 'moving', 'reached', 'leodicaprio', 'exist', 'ignoring', 'turns', 'danger', 'huffingtonpost', 'plant', 'include', 'leecamp', 'phrase', 'different', 'only', 'fucking', 'cartoon', 'potus', 'asked', 'calls', 'thinks', 'usa', 'request', 'extreme', 'york', 'paper', 'rain', 'criticizes', 'schwarzenegger', 'fuel', 'removed', 'election', 'maps', 'century', 'ill', 'agree', 'sweeping', 'early', 'how', 'student', 'terrorism', 'stage', 'own', 'threatened', 'of', 'billmckibben', 'boss', 'snow', 'race', 'understands', 'gender', 'alias', 'dicaprios', 'strategy', 'omg', 'hour', 'sun', 'facts', 'turnbull', 'online', 'kills', 'alone', 'cost', 'dup', 'risk', 'cope', 'tãââ', 'poll', 'thought', 'shift', 'morocco', 'block', 'made', 'astrokatie', 'emissions', 'remember', 'manipulated', 'indian', 'worldfnature', 'researchers', 'during', 'book', 'management', 'taking', 'do', 'refuses', 'causes', 'inconvenient', 'areas', 'does', 'afford', 'justintrudeau', 'moment', 'soil', 'clinton', 'myth', 'mark', 'co', 'so', 'vegan', 'macron', 'clean', 'rising', 'id', 'grist', 'davidsirota', 'petition', 'stay', 'conservatives', 'mattis', 'these', 'related', 'space', 'burning', 'star', 'david', 'preventing', 'no', 'though', 'risks', 'forget', 'state', 'secret', 'fund', 'jobs', 'official', 'floods', 'warned', 'say', 'exit', 'contributor', 'noaa', 'total', 'progress', 'discussions', 'biggest', 'perry', 'perspective', 'websites', 'believe', 'coastal', 'antiscience', 'govt', 'm', 'review', 'reacts', 'largest', 'businesses', 'terms', 'coverage', 'justice', 'ignores', 'tweet', 'weather', 'nato', 'realize', 'financial', 'ad', 'religion', 'hurricane', 'ceo', 'teaching', 'misled', 'ask', 'driver', 'further', 'otherwise', 'far', 'farmers', 'glad', 'protest', 'send', 'reversing', 'due', 'delay', 'wrong', 'down', 'gt', 'every', 'gay', 'economic', 'executive', 'wrote', 'overwhelming', 'cities', 'stephen', 'sky', 'here', 'hearing', 'nature', 'china', 'voter', 'been', 'can', 'blow', 'climatemarch', 'simply', 'refuse', 'business', 'responsible', 'movie', 'research', 'endangered', 'job', 'called', 'believes', 'greenpeaceusa', 'temperatures', 'year', 'december', 'businessinsider', 'di', 'led', 'vladimir', 'deforestation', 'yearsofliving', 'canceled', 'cnbc', 'something', 'actonclimate', 'quick', 'abortion', 'warming', 'voters', 'hurt', 'lot', 'breaking', 'take', 'shot', 'political', 'vital', 'ãâ', 'webpage', 'stop', 'htt', 'challenge', 'fraud', 'ht', 'texas', 'large', 'bbc', 'covered', 'reading', 'scientist', 'article', 'popular', 'warn', 'cover', 'ass', 'the', 'destroying', 'bold', 'comes', 'well', 'leave', 'amazing', 'emails', 'starts', 'morning', 'billnye', 'away', 'rich', 'and', 'red', 'created', 't', 'day', 'bears', 'step', 'continues', 'new', 'korea', 'john', 'damn', 'territory', 'epas', 'worst', 'many', 'stance', 'company', 'reasons', 'whos', 'gores', 'tree', 'manmade', 'trying', 'set', 'apple', 'full', 'waves', 'apparently', 'afraid', 'isis', 'took', 'some', 'powerful', 'transition', 'along', 'climateprogress', 'florida', 'context', 'concerned', 'him', 'consequence', 'costs', 'essential', 'biodiversity', 'truth', 'kerry', 'moon', 'popsci', 'first', 'climatecounts', 'places', 'pushes', 'miss', 'telling', 'carbon', 'but', 'httpstco', 'thing', 'brexit', 'urban', 'food', 'slate', 'gon', 'stuff', 'protesters', 'obama', 'move', 'mike', 'retreat', 'five', 'cf', 'legit', 'shocking', 'books', 'increasing', 'car', 'discussing', 'firms', 'causing', 'invent', 'hottest', 'bottles', 'towards', 'see', 'tracker', 'survive', 'hate', 'documents', 'reject', 'special', 'address', 'pick', 'fire', 'try', 'strong', 'wake', 'season', 'explains', 'issue', 'her', 'leo', 'ahead', 'seen', 'begins', 'slow', 'science', 'sensanders', 'blog', 'source', 'humancaused', 'safetypindaily', 'hey', 'reefs', 'hours', 'list', 'watch', 'affects', 'affecting', 'be', 'global', 'may', 'disappeared', 'humans', 'renewable', 'legacy', 'antarctic', 'did', 'face', 'michaelemann', 'into', 'reason', 'makes', 'their', 'climatechangrr', 'help', 'reducing', 'altnatparkser', 'foe_us', 'happen', 'violence', 'real', 'saving', 'military', 'wont', 'economy', 'exactly', 'havent', 'san', 'ancient', 'wisconsin', 'go', 'arent', 'wef', 'candidate', 'spend', 'animals', 'opinion', 'deaths', 'im', 'billmoyershq', 'favor', 'conservative', 'h', 'huge', 'immediate', 'bye', 'mental', 'watching', 'off', 'starting', 'public', 'need', 'run', 'acting', 'p', 'independent', 'together', 'doubts', 'body', 'days', 'loss', 'influence', 'ãââ', 'affect', 'politico', 'boost', 'recent', 'on', 'went', 'events', 'kinda', 'time', 'energy', 'department', 'kurteichenwald', 'we', 'sad', 'bigger', 'song', 'read', 'you', 'wealth', 'paying', 'lies', 'funny', 'yet', 'less', 'kids', 'ag', 'pushing', 'hope', 'reform', 'youth', 'algae', 'never', 'unstoppable', 'bet', 'key', 'get', 'george', 'fuels', 'enjoy', 'httãââ', 'possible', 'markruffalo', 'mitigating', 'models', 'interesting', 'giving', 'film', 'programs', 'citizens', 'wow', 'central', 'wired', 'latest', 'wage', 'ignore', 'facing', 'network', 'charles', 'contributes', 'methane', 'create', 'wasted', 'child', 'reef', 'world', 'removes', 'serious', 'k', 'yrs', 'effects', 'studies', 'clear', 'activity', 'not', 'west', 'write', 'explain', 'agreed', 'cant', 'kill', 'tackling', 'park', 'supports', 'wait', 'two', 'she', 'hell', 'years', 'wan', 'bitch', 'enjoying', 'reduce', 'debating', 'ban', 'judge', 'arctic', 'worry', 'sceptics', 'skeptic', 'drought', 'dramatically', 'c', 'dude', 'preserving', 'yesterday', 'thehill', 'launch', 'duped', 'likely', 'mashable', 'rex', 'fights', 'false', 'mayors', 'dangers', 'happening', 'lawsuit', 'consensus', 'human', 'cnni', 'theory', 'lied', 'fake', 'totally', 'talks', 'million', 'coral', 'climateaction', 'wtf', 'home', 'leaders', 'troubling', 'ny', 'dioxide', 'map', 'deniers', 'groups', 'across', 'latimes', 'lots', 'climatenexus', 'getting', 'penguin', 'actually', 'tillerson', 'known', 'nyt', 'insane', 'nation', 'nytscience', 'society', 'committed', 'accept', 'deny', 'its', 'agency', 'last', 'normal', 'coal', 'fracking', 'envdefensefund', 'giant', 'conversation', 'land', 'play', 'conflict', 'senatormroberts', 'check', 'unchecked', 'order', 'copy', 'hot', 'view', 'rare', 'topic', 'ccities', 'urged', 'role', 'between', 'keep', 'threatens', 'arnold', 'retweeted', 'march', 'spring', 'invented', 'security', 'catastrophe', 'canada', 'driving', 'rest', 'denialism', 'nice', 'soils', 'over', 'agreement', 'needs', 'suffer', 'dems', 'ended', 'back', 'activist', 'too', 'if', 'trade', 'my', 'feeling', 'insurance', 'importance', 'children', 'university', 'hurricanes', 'proof', 'model', 'hillaryclinton', 'emergency', 'gets', 'seems', 'okay', 'agriculture', 'finds', 'angry', 'late', 'information', 'pole', 'designed', 'evolution', 'man', 'australian', 'nd', 'spending', 'majority', 'building', 'humanity', 'inaction', 'crime', 'toll', 'community', 'pacific', 'contradicts', 'discuss', 'shouldnt', 'guardianeco', 'next', 'fun', 'pablorodas', 'making', 'general', 'equality', 'site', 'democrat', 'welcome', 'beat', 'berlin', 'iãââm', 'fail', 'amazon', 'support', 'were', 'mid', 'dealing', 'letter', 'callers', 'system', 'evidence', 'house', 'elect', 'critical', 'web', 'trigger', 'supporting', 'prince', 'pence', 'start', 'lgbtq', 'christian', 'college', 'tells', 'hypocrite', 'rogue', 'since', 'dad', 'now', 'obviously', 'incredible', 'worlds', 'feels', 'single', 'united', 'heres', 'raise', 'are', 'prepare', 'ocean', 'paris', 'reindeer', 'short', 'below', 'regulations', 'target', 'asking', 'nations', 'higher', 'drives', 'fires', 'conference', 'front', 'change', 'sorry', 'points', 'tveitdal', 'black', 'rights', 'theblaze', 'law', 'suggests', 'honestly', 'investment', 'link', 'sector', 'his', 'interactive', 'friends', 'decisions', 'saying', 'bullshit', 'decades', 'algore', 'a', 'idiots', 'maybe', 'brown', 'fast', 'atmosphere', 'under', 'let', 'plans', 'smh', 'coming', 'night', 'there', 'february', 'happened', 'ha', 'infrastructure', 'shuts', 'crap', 'sue', 'europe', 'solution', 'n', 'd', 'eye', 'pretend', 'b', 'mother', 'officials', 'november', 'contribute', 'failure', 'stronger', 'by', 'open', 'sign', 'studying', 'massive', 'before', 'control', 'chance', 'greatest', 'buy', 'idiot', 'attacks', 'history', 'lost', 'despite', 'la', 'sustainability', 'rolling', 'media', 'double', 'planet', 'attack', 'links', 'belief', 'bank', 'british', 'tackle', 'mitigate', 'london', 'resist', 'voices', 'scott', 'knew', 'push', 'bring', 'once', 'found', 'suing', 'national', 'level', 'won', 'natgeochannel', 'irrefutable', 'who', 'hold', 'reports', 'politifact', 'proves', 'speaking', 'changes', 'goal', 'panel', 'absolutely', 'mitigation', 'malcolm', 'percent', 'discussion', 'etc', 'past', 'racism', 'times', 'citizensclimate', 'ur', 'cop', 'vote', 'companies', 'twitter', 'pm', 'top', 'budget', 'dead', 'devastating', 'country', 'all', 'team', 'greenhouse', 'around', 'sense', 'fear', 'fix', 'nyc', 'nope', 'cnvey', 'bad', 'plants', 'given', 'pull', 'nye', 'very', 'hi', 'industry', 'however', 'safety', 'god', 'stopped', 'happy', 'power', 'amp', 'women', 'give', 'cares', 'guy', 'whats', 'our', 'impacts', 'em', 'fucked', 'images', 'minutes', 'qanda', 'presidents', 'speech', 'got', 'conservation', 'supported', 'struggle', 'undo', 'committee', 'everyone', 'primary', 'photo', 'cut', 'australia', 'admin', 'come', 'jet', 'trumps', 'or', 'best', 'eu', 'april', 'showing', 'south', 'uncontrollable', 'extremely', 'concept', 'website', 'growing', 'hired', 'presentation', 'billion', 'theyll', 'contributing', 'means', 'population', 'pres', 'done', 'fired', 'taxes', 'left', 'immigration', 'tomorrow', 'yes', 'peace', 'admits', 'mentions', 'withdraw', 'end', 'ready', 'environmental', 'entire', 'longterm', 'lmao', 'exxon', 'republicans', 'stupid', 'summer', 'changing', 'worried', 'administrator', 'laws', 'flooding', 'vaccines', 'little', 'foxnews', 'faster', 'v', 'your', 'mobil', 'spent', 'thats', 'ground', 'directly', 'youll', 'puanconference', 'accord', 'investors', 'will', 'thanks', 'disasters', 'hear', 'direct', 'forward', 'protecting', 'common', 'then', 'victims', 'chelseaclinton', 'federal', 'scam', 'same', 'experts', 'forest', 'droughts', 'beginning', 'continue', 'disease', 'shows', 'leaves', 'lgbt', 'visit', 'warning', 'fish', 'eating', 'much', 'series', 'another', 'minister', 'private', 'chinese', 'canary', 'also', 'fighting', 'jerry', 'anti', 'moral', 'except', 'merkel', 'worked', 'momentum', 'save', 'gates', 'anyone', 'existence', 'alaska', 'inauguration', 'birds', 'among', 'doing', 'cooling', 'optimistic', 'defense', 'uses', 'questions', 'losing', 'spread', 'doc', 'hasnt', 'references', 'resources', 'pathetic', 'small', 'soon', 'ridiculous', 'including', 'most', 'future', 'wasnt', 'main', 'scary', 'crop', 'pollution', 'climatereality', 'minute', 'acknowledge', 'settled', 'than', 'proven', 'weapons', 'policies', 'beef', 'looking', 'issues', 'putting', 'nrdc', 'gov', 'nowthisnews', 'helps', 'st', 'projects', 'santa', 'better', 'instead', 'possibly', 'half', 'bs', 'drop', 'motherboard', 'moron', 'hoax', 'scale', 'up', 'picks', 'gave', 'report', 'reminder', 'think', 'turn', 'dc', 'australias', 'tv', 'f', 'epascottpruitt', 'vice', 'mass', 'please', 'major', 'heat', 'flat', 'want', 'where', 'urgent', 'high', 'predictions', 'water', 'orders', 'stand', 'north', 'care', 'rick', 'per', 'live', 'cc', 'barrier', 'mikebloomberg', 'us', 'answer', 'work', 'npr', 'place', 'started', 'bc', 'make', 'die', 'prof', 'http', 'huffpostpol', 'greenpeace', 'fiction', 'newsweek', 'used', 'reporting', 'whatever', 'like', 'game', 'pause', 'summit', 'sciam', 'positions', 'find', 'opportunity', 'cool', 'barack', 'problems', 'might', 'concern', 'men', 'concerns', 'idea', 'excellent', 'thinkprogress', 'director', 'challenges', 'governments', 'politics', 'case', 'liberal', 'mad', 'httpsãââ', 'guide', 'guardian', 'he', 'roll', 'ericholthaus', 'sit', 'changed', 'cnnmoney', 'thinking', 'outside', 'ten', 'cuts', 'u', 'pruitts', 'talk', 'climatecentral', 'advance', 'nuclear', 'republican', 'helping', 'old', 'core', 'must', 'weve', 'meeting', 'wars', 'seriously', 'states', 'number', 'survey', 'oklahoma', 'leonardo', 'o', 'solar', 'urges', 'environment', 'just', 'river', 'religious', 'in', 'access', 'modern', 'realdonaldtrump', 'france', 'name', 'effect', 'whole', 'surprise', 'healthcare', 'knows', 'takes', 'consequences', 'more', 'killed', 'unep', 'proposed', 'greatbarrierreef', 'having', 'earthday', 'seem', 'tech', 'choose', 'knowledge', 'ajplus', 'leading', 'communities', 'timelapse', 'meet', 'interest', 'accelerate', 'presidential', 'any', 'government', 'combating', 'secretary', 'light', 'expert', 'few', 'hiatus', 'foreign', 'party', 'nasa', 'while', 'african', 'three', 'caps', 'becomes', 'vulnerable', 'completely', 'mean', 'cabinet', 'build', 'canadian', 'wear', 'sexist', 'altusepa', 'an', 'elected', 'warm', 'httpstcoãââ', 'point', 'wearing', 'httpstc', 'talking', 'journalists', 'grand', 'action', 'civil', 'already', 'coast', 'bill', 'cause', 'weeks', 'death', 'pact', 'lying', 'blaming', 'reuters', 'what', 'bernie', 'claim', 'r', 'dear', 'scared', 'anything', 'told', 'exxonmobil', 'fascist', 'skeptics', 'beforetheflood', 'steps', 'working', 'even', 'poor', 'deleted', 'abandoning', 'especially', 'dana', 'kind', 'crisis', 'teach', 'breitbart', 'parks', 'deadly', 'destroy', 'uncharted', 'solutions', 'after', 'probably', 'movement', 'internet', 'money', 'eat', 'l', 'ãââœ', 'httpstãââ', 'developed', 'denies', 'smog', 'presidentelect', 'conspiracy', 'deep', 'least', 'diseases', 'column', 'study', 'faces', 'either', 'with', 'governor', 'tank', 'tonight', 'politicians', 'lol', 'sick', 'bees', 'potential', 'threatening', 'decided', 'statement', 'trust', 'would', 'americans', 'pa', 'marriage', 'actions', 'winter', 'factor', 'lawson', 'week', 'side', 'technology', 'else', 'youd', 'hit', 'salon', 'goals', 'presidency', 'threats', 'via', 'fall', 'effort', 'problem', 'httpst', 'nuccitelli', 'lie', 'am', 'denial', 'mayor', 'eyes', 'thousands', 'couldnt', 'initiative', 'released', 'womens', 'underwater', 'actual', 'famine', 'ignored', 'ft', 'isnt', 'respond', 'hates', 'development', 'yourself', 'adapt', 'understanding', 'levels', 'physics', 'thoughts', 'youtube', 'propaganda', 'why', 'great', 'anxiety', 'enough', 'funding', 'sure', 'prevent', 'recordbreaking', 'war', 'g', 'gore', 'reverse', 'fusion', 'pesticides', 'policy', 'dont', 'battle', 'democrats', 'dollars', 'corporate', 'rejects', 'staff', 'heart', 'earth', 'advisory', 'folks', 'win', 'important', 'free', 'six', 'finally', 'debates', 'adaptation', 'catastrophic', 'remove', 'focus', 'badlands', 'going', 'international', 'seas', 'threat', 'ago', 'charge', 'beyond', 'shes', 'blame', 'argue', 'each', 'about', 'denied', 'court', 'driven', 'fact', 'guess', 'oceans', 'leader', 'mention', 'benefits', 'show', 'kylegriffin', 'sec', 'msnbc', 'cars', 'pay', 'farming', 'targets', 'leadership', 'extinct', 'james', 'increased', 'ignorance', 'ignorant', 'anthropogenic', 'those', 'resistance', 'peoples', 'natgeo', 'expect', 'wild', 'todays', 'knowing', 'mr', 'offers', 'htãââ', 'glaciers', 'person', 'yr', 'scientific', 'approach', 'degree', 'grow', 'washingtonpost', 'americas', 'guys', 'extinction', 'shut', 'plan', 'solve', 'climatehawk', 'hand', 'marine', 'roberts', 'someone', 'friend', 'coalition', 'radical', 'combat', 'months', 'convinced', 'awareness', 'out', 'animal', 'anyway', 'dies', 'anymore', 'matter', 'worse', 'failing', 'consider', 'could', 'literally', 'air', 'until', 'harvey', 'taken', 'commitments', 'later', 'four', 'is', 'expected', 'sustainable', 'talked', 'shell', 'uk', 'th', 'attend', 'denier', 'abc', 'signed', 'decision', 'degrees', 'pls', 'turned', 'example', 'social', 'super', 'affected', 'news', 'word', 'fight', 'dying', 'cancels', 'they', 'al', 'looks', 'gravity', 'often', 'aim', 'summers', 'said', 'good', 'which', 'brain', 'school', 'keeping', 'chief', 'nasas', 'ecointernet', 'lord', 'billions', 'video', 'wh', 'planning', 'employees', 'ok', 'toward', 'announce', 'sunday', 'senate', 'limit', 'town', 'tan', 'ge', 'parking', 'cooked', 'germany', 'reviews', 'lawmakers', 'blames', 'emanuel', 'cbcnews', 'whistleblower', 'whistle', 'cancel', 'meets', 'obamaera', 'vows', 'blower', 'blamed', 'charges', 'libs', 'snowflakes', 'prisonplanet', 'stevesgoddard', 'alarmists', 'enlist']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We use a Vector, called CountVectorizer to convert a collection of text in to token counts","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ndf_clean = df_tr.copy()\nX = df_clean['message']\ny = df_clean['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:43.196653Z","iopub.execute_input":"2022-10-12T13:08:43.197102Z","iopub.status.idle":"2022-10-12T13:08:43.215378Z","shell.execute_reply.started":"2022-10-12T13:08:43.197064Z","shell.execute_reply":"2022-10-12T13:08:43.213670Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Lets have a look at the distribution in our Y class","metadata":{}},{"cell_type":"code","source":"#We first need to seperate the data in to train test splits\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:11:29.798250Z","iopub.execute_input":"2022-10-12T13:11:29.798638Z","iopub.status.idle":"2022-10-12T13:11:29.811719Z","shell.execute_reply.started":"2022-10-12T13:11:29.798610Z","shell.execute_reply":"2022-10-12T13:11:29.809661Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Now that we have analysed and prepared the data, we will start building some classification models.\nWe will use the following models in this predict:\n- Logistic Regression \n- Nearest Neighbors \n- Linear SVM\n- RBF SVM,          \n- Random Forest\n\nOnce we build the models, we will get the following results for each model output:\n- Classification Report\n- Accuracy score\n- Precision Score\n- F1 score","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\n\n\n# Random Forest Classifier\nrf = Pipeline([('tfidf', TfidfVectorizer()),\n               ('clf', RandomForestClassifier(max_depth=5, \n                                              n_estimators=100))])\n\n# Naïve Bayes:\nnb = Pipeline([('tfidf', TfidfVectorizer()),\n               ('clf', MultinomialNB())])\n\n# K-NN Classifier\nknn = Pipeline([('tfidf', TfidfVectorizer()),\n                ('clf', KNeighborsClassifier(n_neighbors=5, \n                                             metric='minkowski', \n                                             p=2))])\n\n# Logistic Regression\nlr = Pipeline([('tfidf',TfidfVectorizer()),\n               ('clf',LogisticRegression(C=1, \n                                         class_weight='balanced', \n                                         max_iter=1000))])\n# Linear SVC:\nlsvc = Pipeline([('tfidf', TfidfVectorizer()),\n                 ('clf', LinearSVC(class_weight='balanced'))])","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:11:39.944994Z","iopub.execute_input":"2022-10-12T13:11:39.945584Z","iopub.status.idle":"2022-10-12T13:11:39.953504Z","shell.execute_reply.started":"2022-10-12T13:11:39.945553Z","shell.execute_reply":"2022-10-12T13:11:39.952393Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"results = []\n\n# Random forest \nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\nresults.append(['Random Forest',metrics.accuracy_score(y_test,y_pred_rf),metrics.precision_score(y_test,y_pred_rf,average='weighted'),metrics.recall_score(y_test,y_pred_rf,average='weighted'),metrics.f1_score(y_test,y_pred_rf,average='weighted')])\n\n# Niave bayes\nnb.fit(X_train, y_train)\ny_pred_nb = nb.predict(X_test)\nresults.append(['Niave Bayes',metrics.accuracy_score(y_test,y_pred_nb),metrics.precision_score(y_test,y_pred_nb,average='weighted'),metrics.recall_score(y_test,y_pred_nb,average='weighted'),metrics.f1_score(y_test,y_pred_nb,average='weighted')])\n\n\n# K - nearest neighbors\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\nresults.append(['Nearest Neighbors',metrics.accuracy_score(y_test,y_pred_knn),metrics.precision_score(y_test,y_pred_knn,average='weighted'),metrics.recall_score(y_test,y_pred_knn,average='weighted'),metrics.f1_score(y_test,y_pred_knn,average='weighted')])\n\n\n# Linear regression\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\nresults.append(['Logistic Regression',metrics.accuracy_score(y_test,y_pred_lr),metrics.precision_score(y_test,y_pred_lr,average='weighted'),metrics.recall_score(y_test,y_pred_lr,average='weighted'),metrics.f1_score(y_test,y_pred_lr,average='weighted')])\n\n\n# Linear SVC\nlsvc.fit(X_train, y_train)\ny_pred_lsvc = lsvc.predict(X_test)\nresults.append(['Linear SVM',metrics.accuracy_score(y_test,y_pred_lsvc),metrics.precision_score(y_test,y_pred_lsvc,average='weighted'),metrics.recall_score(y_test,y_pred_lsvc,average='weighted'),metrics.f1_score(y_test,y_pred_lsvc,average='weighted')])\n\n\nresults = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Test'])\nresults.set_index('Classifier', inplace= True)\nresults.sort_values('F1 Test', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:21:02.747117Z","iopub.execute_input":"2022-10-12T13:21:02.747492Z","iopub.status.idle":"2022-10-12T13:21:11.785140Z","shell.execute_reply.started":"2022-10-12T13:21:02.747463Z","shell.execute_reply":"2022-10-12T13:21:11.783629Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                     Accuracy  Precision    Recall   F1 Test\nClassifier                                                  \nLinear SVM           0.717498   0.705756  0.717498  0.709278\nLogistic Regression  0.690794   0.698403  0.690794  0.691981\nNearest Neighbors    0.629656   0.616692  0.629656  0.618430\nNiave Bayes          0.585032   0.671257  0.585032  0.483466\nRandom Forest        0.510541   0.509591  0.510541  0.345884","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Test</th>\n    </tr>\n    <tr>\n      <th>Classifier</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Linear SVM</th>\n      <td>0.717498</td>\n      <td>0.705756</td>\n      <td>0.717498</td>\n      <td>0.709278</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.690794</td>\n      <td>0.698403</td>\n      <td>0.690794</td>\n      <td>0.691981</td>\n    </tr>\n    <tr>\n      <th>Nearest Neighbors</th>\n      <td>0.629656</td>\n      <td>0.616692</td>\n      <td>0.629656</td>\n      <td>0.618430</td>\n    </tr>\n    <tr>\n      <th>Niave Bayes</th>\n      <td>0.585032</td>\n      <td>0.671257</td>\n      <td>0.585032</td>\n      <td>0.483466</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.510541</td>\n      <td>0.509591</td>\n      <td>0.510541</td>\n      <td>0.345884</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We are going to create a dataframe with the outcomes of the scoring, and we will be able to see which model performed the best, based on the various models\n","metadata":{}},{"cell_type":"markdown","source":"We are doing additional classification verification by implementing the confusion matrix as well as the classification report\n","metadata":{}},{"cell_type":"code","source":"#Confusion matrix:\nfrom sklearn.metrics import confusion_matrix\n\nlabels = ['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']\n\n#Logistic Regression\ndf_LRCM = pd.DataFrame(data=confusion_matrix(y_test,y_pred_lr), index=labels, columns = labels)\nprint('Logistic Regression')\ndisplay(df_LRCM)\n\n#Linear SVM\ndf_lsvmCM = pd.DataFrame(data=confusion_matrix(y_test,y_pred_lsvc), index=labels, columns = labels)\nprint('Linear SVM')\ndisplay(df_lsvmCM)\n\n\n#Rand Forests\ndf_randCM = pd.DataFrame(data=confusion_matrix(y_test,y_pred_rf), index=labels, columns = labels)\nprint('Linear SVM')\ndisplay(df_randCM)\n\n#KNN\ndf_nnCM = pd.DataFrame(data=confusion_matrix(y_test,y_pred_knn), index=labels, columns = labels)\nprint('Linear SVM')\ndisplay(df_nnCM)\n\n#Niave bayes\ndf_nnNB = pd.DataFrame(data=confusion_matrix(y_test,y_pred_nb), index=labels, columns = labels)\nprint('Linear SVM')\ndisplay(df_nnNB)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:23:41.212734Z","iopub.execute_input":"2022-10-12T13:23:41.213109Z","iopub.status.idle":"2022-10-12T13:23:41.274922Z","shell.execute_reply.started":"2022-10-12T13:23:41.213083Z","shell.execute_reply":"2022-10-12T13:23:41.273642Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Logistic Regression\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            -1: Anti  0: Neutral  1: Pro  2: News\n-1: Anti         134          48      43       17\n0: Neutral        45         207     146       45\n1: Pro            82         181    1024      164\n2: News           10          22      77      601","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-1: Anti</th>\n      <th>0: Neutral</th>\n      <th>1: Pro</th>\n      <th>2: News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1: Anti</th>\n      <td>134</td>\n      <td>48</td>\n      <td>43</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>0: Neutral</th>\n      <td>45</td>\n      <td>207</td>\n      <td>146</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1: Pro</th>\n      <td>82</td>\n      <td>181</td>\n      <td>1024</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>2: News</th>\n      <td>10</td>\n      <td>22</td>\n      <td>77</td>\n      <td>601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Linear SVM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            -1: Anti  0: Neutral  1: Pro  2: News\n-1: Anti         115          39      73       15\n0: Neutral        37         174     190       42\n1: Pro            45         107    1179      120\n2: News            5          16     115      574","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-1: Anti</th>\n      <th>0: Neutral</th>\n      <th>1: Pro</th>\n      <th>2: News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1: Anti</th>\n      <td>115</td>\n      <td>39</td>\n      <td>73</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>0: Neutral</th>\n      <td>37</td>\n      <td>174</td>\n      <td>190</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>1: Pro</th>\n      <td>45</td>\n      <td>107</td>\n      <td>1179</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>2: News</th>\n      <td>5</td>\n      <td>16</td>\n      <td>115</td>\n      <td>574</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Linear SVM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            -1: Anti  0: Neutral  1: Pro  2: News\n-1: Anti           0           0     242        0\n0: Neutral         0           0     443        0\n1: Pro             0           0    1451        0\n2: News            0           0     708        2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-1: Anti</th>\n      <th>0: Neutral</th>\n      <th>1: Pro</th>\n      <th>2: News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1: Anti</th>\n      <td>0</td>\n      <td>0</td>\n      <td>242</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0: Neutral</th>\n      <td>0</td>\n      <td>0</td>\n      <td>443</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1: Pro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1451</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2: News</th>\n      <td>0</td>\n      <td>0</td>\n      <td>708</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Linear SVM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            -1: Anti  0: Neutral  1: Pro  2: News\n-1: Anti          74          45     105       18\n0: Neutral        39         136     242       26\n1: Pro            47         137    1140      127\n2: News           16          35     217      442","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-1: Anti</th>\n      <th>0: Neutral</th>\n      <th>1: Pro</th>\n      <th>2: News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1: Anti</th>\n      <td>74</td>\n      <td>45</td>\n      <td>105</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>0: Neutral</th>\n      <td>39</td>\n      <td>136</td>\n      <td>242</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1: Pro</th>\n      <td>47</td>\n      <td>137</td>\n      <td>1140</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>2: News</th>\n      <td>16</td>\n      <td>35</td>\n      <td>217</td>\n      <td>442</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Linear SVM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            -1: Anti  0: Neutral  1: Pro  2: News\n-1: Anti           0           0     240        2\n0: Neutral         0          14     426        3\n1: Pro             0           0    1442        9\n2: News            0           0     501      209","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-1: Anti</th>\n      <th>0: Neutral</th>\n      <th>1: Pro</th>\n      <th>2: News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1: Anti</th>\n      <td>0</td>\n      <td>0</td>\n      <td>240</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0: Neutral</th>\n      <td>0</td>\n      <td>14</td>\n      <td>426</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1: Pro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1442</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2: News</th>\n      <td>0</td>\n      <td>0</td>\n      <td>501</td>\n      <td>209</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#classification Report\nprint(\"logistic Regression\")\nprint(classification_report(y_test, lr_pred, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))\n\nprint(\"Linear SVM\")\nprint(classification_report(y_test, svclin_pred, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))\n\nprint(\"rbf SVM\")\nprint(classification_report(y_test, svcrbf_pred, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))\n\nprint(\"Random Forests\")\nprint(classification_report(y_test, rand_pred, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))\n\nprint(\"KNN\")\nprint(classification_report(y_test, nn_pred, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:43.380152Z","iopub.status.idle":"2022-10-12T13:08:43.380507Z","shell.execute_reply.started":"2022-10-12T13:08:43.380322Z","shell.execute_reply":"2022-10-12T13:08:43.380337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the validation scores above, we notice that the weighted average scores are on the low side. \nBy understanding this, we can try to improve our models, by further analyzing data. \n\nFrom the above analysis, we will select the 2 best performing models, and try to make improvements on those\n\nWe will be using the following techniques to try and improve our model:\n- Choosing K Best Features\n- Hyper Parameter Tuning","metadata":{}},{"cell_type":"code","source":"#Choosing K Best Features on the Logistical Model\nfrom sklearn import feature_selection\nfrom sklearn.feature_selection import f_classif\n\nlm_kbest = LogisticRegression(solver='lbfgs')\nselector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=8613)\nX_train_kbest = selector_kbest.fit_transform(X_train, y_train)\ndisplay(X_train_kbest.shape)\nX_train.shape\n\n#fit the k best model \nlm_kbest.fit(X_train_kbest, y_train)\n\n#Converting test data as well\nX_test_kbest = selector_kbest.transform(X_test)\n\n#Performing the prediction\npred_lm_kbest = lm_kbest.predict(X_test_kbest)\n\n#Assessing the prediction\n\nprint(classification_report(y_test, pred_lm_kbest, target_names=['-1: Anti' , '0: Neutral' , '1: Pro' , '2: News']))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:08:43.384938Z","iopub.status.idle":"2022-10-12T13:08:43.385427Z","shell.execute_reply.started":"2022-10-12T13:08:43.385227Z","shell.execute_reply":"2022-10-12T13:08:43.385247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrain linear SVC using optimal hyperparameters:\nlsvc_op = Pipeline([('tfidf', TfidfVectorizer(max_df=0.8,\n                                                    min_df=2,\n                                                    ngram_range=(1,2))),\n                  ('clf', LinearSVC(C=0.3,\n                                    class_weight='balanced',\n                                    max_iter=3000))])\nlsvc_op.fit(X_train,y_train)\nfinal_pred = lsvc_op.predict(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:36:27.451775Z","iopub.execute_input":"2022-10-12T13:36:27.452155Z","iopub.status.idle":"2022-10-12T13:36:28.232701Z","shell.execute_reply.started":"2022-10-12T13:36:27.452128Z","shell.execute_reply":"2022-10-12T13:36:28.231131Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"After Tuning the hyper parameters of the best performing Model, we will compare the previous linear SVC score to test improvement\n","metadata":{}},{"cell_type":"code","source":"before_f1 = metrics.f1_score(y_test,y_pred_lr,average='weighted') \nafter_f1 = metrics.f1_score(y_test,final_pred,average='weighted')\n\nprint (before_f1)\nprint (after_f1)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:36:32.236404Z","iopub.execute_input":"2022-10-12T13:36:32.236792Z","iopub.status.idle":"2022-10-12T13:36:32.249399Z","shell.execute_reply.started":"2022-10-12T13:36:32.236765Z","shell.execute_reply":"2022-10-12T13:36:32.247425Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"0.6919805550851696\n0.7222422611653255\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, we will use the best model, and do the submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/edsa-sentiment-classification/test.csv')\nfinal_test = lsvc_op.predict(test['message'])\noutput = pd.DataFrame({'tweetid': test.tweetid,\n                       'sentiment': final_test})\noutput.to_csv('C:\\\\Users\\\\abyj052\\\\OneDrive - Absa\\\\Yusuf Work\\\\Learning\\\\Data Science\\\\Advanced Classification\\\\Predict\\\\submission.csv', index=False)\noutput","metadata":{"execution":{"iopub.status.busy":"2022-10-12T13:51:20.986703Z","iopub.execute_input":"2022-10-12T13:51:20.987109Z","iopub.status.idle":"2022-10-12T13:51:21.437682Z","shell.execute_reply.started":"2022-10-12T13:51:20.987081Z","shell.execute_reply":"2022-10-12T13:51:21.436594Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"       tweetid  sentiment\n0       169760          1\n1        35326          1\n2       224985          1\n3       476263          1\n4       872928          0\n...        ...        ...\n10541   895714          1\n10542   875167          1\n10543    78329          2\n10544   867455          0\n10545   470892          0\n\n[10546 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetid</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>169760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35326</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>224985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>476263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>872928</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10541</th>\n      <td>895714</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10542</th>\n      <td>875167</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10543</th>\n      <td>78329</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10544</th>\n      <td>867455</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10545</th>\n      <td>470892</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10546 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}